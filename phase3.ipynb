{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feff3bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chala\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\chala\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "844/844 - 5s - 6ms/step - accuracy: 0.8006 - loss: 1.0778 - val_accuracy: 0.8345 - val_loss: 0.7606\n",
      "Epoch 2/20\n",
      "844/844 - 3s - 4ms/step - accuracy: 0.8352 - loss: 0.7066 - val_accuracy: 0.8578 - val_loss: 0.5908\n",
      "Epoch 3/20\n",
      "844/844 - 3s - 4ms/step - accuracy: 0.8414 - loss: 0.6098 - val_accuracy: 0.8392 - val_loss: 0.5855\n",
      "Epoch 4/20\n",
      "844/844 - 4s - 4ms/step - accuracy: 0.8442 - loss: 0.5796 - val_accuracy: 0.8508 - val_loss: 0.5631\n",
      "Epoch 5/20\n",
      "844/844 - 3s - 4ms/step - accuracy: 0.8475 - loss: 0.5573 - val_accuracy: 0.8423 - val_loss: 0.5654\n",
      "Epoch 6/20\n",
      "844/844 - 4s - 4ms/step - accuracy: 0.8463 - loss: 0.5566 - val_accuracy: 0.8320 - val_loss: 0.5886\n",
      "Epoch 7/20\n",
      "844/844 - 4s - 4ms/step - accuracy: 0.8502 - loss: 0.5423 - val_accuracy: 0.8502 - val_loss: 0.5397\n",
      "Epoch 8/20\n",
      "844/844 - 4s - 4ms/step - accuracy: 0.8502 - loss: 0.5424 - val_accuracy: 0.8537 - val_loss: 0.5438\n",
      "Epoch 9/20\n",
      "844/844 - 4s - 4ms/step - accuracy: 0.8512 - loss: 0.5382 - val_accuracy: 0.8487 - val_loss: 0.5386\n",
      "Epoch 10/20\n",
      "844/844 - 3s - 4ms/step - accuracy: 0.8538 - loss: 0.5329 - val_accuracy: 0.8568 - val_loss: 0.5302\n",
      "Epoch 11/20\n",
      "844/844 - 4s - 4ms/step - accuracy: 0.8512 - loss: 0.5374 - val_accuracy: 0.8298 - val_loss: 0.5645\n",
      "Epoch 12/20\n",
      "844/844 - 4s - 4ms/step - accuracy: 0.8544 - loss: 0.5290 - val_accuracy: 0.8593 - val_loss: 0.4958\n",
      "Epoch 13/20\n",
      "844/844 - 3s - 4ms/step - accuracy: 0.8572 - loss: 0.5230 - val_accuracy: 0.8350 - val_loss: 0.5630\n",
      "Epoch 14/20\n",
      "844/844 - 3s - 4ms/step - accuracy: 0.8552 - loss: 0.5263 - val_accuracy: 0.8520 - val_loss: 0.5155\n",
      "Epoch 15/20\n",
      "844/844 - 3s - 4ms/step - accuracy: 0.8554 - loss: 0.5257 - val_accuracy: 0.8495 - val_loss: 0.5387\n",
      "\n",
      "✅ Test Accuracy: 85.74%\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Regularized Deep Learning Model + TensorBoard Visualization\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, callbacks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime   # for unique TensorBoard log folder names\n",
    "\n",
    "# Load and preprocess data\n",
    "# -----------------------------\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize to range [0, 1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "#  Build the model\n",
    "# -----------------------------\n",
    "model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "\n",
    "    # Dense Layer 1 — He Normal + L2 + BatchNorm + ReLU + Dropout\n",
    "    layers.Dense(256, kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Dense Layer 2 — Glorot + GELU + BatchNorm + Dropout\n",
    "    layers.Dense(128, kernel_initializer='glorot_normal',\n",
    "                 kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('gelu'),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Dense Layer 3 — He + LeakyReLU\n",
    "    layers.Dense(64, kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    # Output Layer — Softmax (10 classes)\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "# -----------------------------\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Setup Callbacks\n",
    "# -----------------------------\n",
    "\n",
    "# EarlyStopping — stop training if val_loss stops improving\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint — save best model automatically\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "#  TensorBoard — log everything for visualization\n",
    "# Each run gets its own timestamped log folder\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "# -----------------------------\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, checkpoint, tensorboard_cb],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "#  Evaluate model\n",
    "# -----------------------------\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "#  Visualize prediction\n",
    "# -----------------------------\n",
    "index = 0\n",
    "pred = model.predict(X_test)\n",
    "plt.imshow(X_test[index], cmap='gray')\n",
    "plt.title(f\"Predicted: {np.argmax(pred[index])} | True: {y_test[index]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ef05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
